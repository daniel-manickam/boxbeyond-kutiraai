# =============================================================================
# AI Platform Environment Configuration
# =============================================================================
# Copy this file to .env and update the values for your environment
# Never commit .env files to version control

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------
# N8N Database (connects to n8n container)
N8N_POSTGRES_DB_TYPE=postgresdb
N8N_POSTGRES_HOST=postgres-n8n
N8N_POSTGRES_USER=root
N8N_POSTGRES_PASSWORD=password
N8N_POSTGRES_DB=n8n
N8N_POSTGRES_PORT=5432

# Product API Database  
PRODUCT_POSTGRES_USER=product_user
PRODUCT_POSTGRES_PASSWORD=your_secure_password_here
PRODUCT_POSTGRES_DB=product_db
PRODUCT_POSTGRES_PORT=5434

# Workflow Engine Database
WORKFLOW_POSTGRES_USER=workflow_user
WORKFLOW_POSTGRES_PASSWORD=your_secure_password_here
WORKFLOW_POSTGRES_DB=workflow_db
WORKFLOW_POSTGRES_PORT=5435

# -----------------------------------------------------------------------------
# Security & Authentication
# -----------------------------------------------------------------------------
# Generate a secure 32-character encryption key
N8N_ENCRYPTION_KEY=super-secret-key

# Generate a secure JWT secret
N8N_USER_MANAGEMENT_JWT_SECRET=even-more-secret

# Hugging Face API Token (Required for AI features)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_TOKEN=your_huggingface_token_here

# -----------------------------------------------------------------------------
# Service Configuration
# -----------------------------------------------------------------------------
# Environment: development, staging, production
ENVIRONMENT=development

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# LLM Configuration (for local Ollama)
LLM_API_KEY=ollama
LLM_MODEL=llama3.1:8b
LLM_BASE_URL=http://host.docker.internal:11434

# Redis Configuration (connects to Redis container)
# Note: Fine-tuning service runs outside Docker, so use localhost
REDIS_URL=redis://localhost:6379/0

# Fine-tuning Service Database URL (connects to product database)
# Note: Fine-tuning service runs outside Docker, so use localhost
DATABASE_URL=postgresql://product_user:your_secure_password_here@localhost:5434/product_db

# Worker Configuration (for fine-tuning service)
MAX_WORKERS=4
TIMEOUT=300

# -----------------------------------------------------------------------------
# File Paths (Adjust for your system)
# -----------------------------------------------------------------------------
# Shared file storage path - Update this to your local path
# Example: /Users/your_username/workspace/file_share
FILE_SHARE_PATH=/path/to/your/shared/files

# -----------------------------------------------------------------------------
# Apple Silicon Requirements
# -----------------------------------------------------------------------------
# This platform uses mlx-lm for fine-tuning which requires Apple Silicon (M1/M2/M3)
# If you're not on Apple Silicon, the fine-tuning service will not work